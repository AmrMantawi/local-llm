# Local LLM

A complete local AI assistant with Speech-to-Text (STT), Large Language Model (LLM), and Text-to-Speech (TTS) capabilities. Run entirely on your machine with no cloud dependencies.

## ğŸš€ Features

- **Speech-to-Text**: Whisper-based transcription
- **Language Model**: Llama-based text generation
- **Text-to-Speech**: Piper-based voice synthesis
- **Voice Activity Detection**: Automatic speech detection
- **Cross-platform**: Linux, macOS, Windows (WSL)
- **Privacy-first**: Everything runs locally

## ğŸ“‹ Requirements

### System Dependencies
- **CMake** 3.16+
- **SDL2** development libraries
- **Python** 3.7+
- **ALSA** (Linux) or **Core Audio** (macOS)

### Ubuntu/Debian
```bash
sudo apt-get update
sudo apt-get install cmake libsdl2-dev python3 python3-pip python3-venv alsa-utils
```

### macOS
```bash
brew install cmake sdl2 python3
```

## ğŸ› ï¸ Quick Setup

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd local-llm
   ```

2. **Run the setup script:**
   ```bash
   chmod +x scripts/setup.sh
   ./scripts/setup.sh
   ```

3. **Download models:**
   - **STT**: Download Whisper models from [Hugging Face](https://huggingface.co/ggerganov/whisper.cpp)
   - **LLM**: Download GGUF models from [Hugging Face](https://huggingface.co/models?search=gguf)
   - **TTS**: Download Piper models from [Hugging Face](https://huggingface.co/rhasspy/piper-voices)

4. **Place models in the correct directories:**
   ```
   models/
   â”œâ”€â”€ stt/     # .bin files (Whisper)
   â”œâ”€â”€ llm/     # .gguf files (Llama)
   â””â”€â”€ tts/     # .onnx files (Piper)
   ```

5. **Run the application:**
   ```bash
   ./build/local-llm
   ```

## ğŸ¯ Usage

1. **Start the application** - it will initialize all backends
2. **Speak into your microphone** - voice activity detection will capture your speech
3. **Wait for transcription** - Whisper will convert speech to text
4. **Get AI response** - Llama will generate a response
5. **Hear the response** - Piper will speak the response back to you

**Controls:**
- Press `Ctrl+C` to exit gracefully

## ğŸ“ Project Structure

```
local-llm/
â”œâ”€â”€ include/           # Header files
â”‚   â”œâ”€â”€ stt.h         # STT interface
â”‚   â”œâ”€â”€ llm.h         # LLM interface
â”‚   â”œâ”€â”€ tts.h         # TTS interface
â”‚   â””â”€â”€ ...           # Implementation headers
â”œâ”€â”€ src/              # Source files
â”‚   â”œâ”€â”€ main.cpp      # Main application
â”‚   â”œâ”€â”€ stt_whisper.cpp
â”‚   â”œâ”€â”€ llm_llama.cpp
â”‚   â””â”€â”€ tts_piper.cpp
â”œâ”€â”€ scripts/          # Utility scripts
â”‚   â”œâ”€â”€ setup.sh      # Setup script
â”‚   â””â”€â”€ speak         # TTS script
â”œâ”€â”€ config/           # Configuration files
â”‚   â””â”€â”€ models.json   # Model paths and settings
â”œâ”€â”€ models/           # Model files (not in git)
â”œâ”€â”€ third_party/      # External dependencies
â””â”€â”€ build/           # Build artifacts (not in git)
```

## âš™ï¸ Configuration

Edit `config/models.json` to customize:
- Model file paths
- Audio settings
- TTS voice settings

## ğŸ”§ Development

### Building from source:
```bash
mkdir build && cd build
cmake ..
make -j$(nproc)
```

### Adding new backends:
1. Create header file in `include/`
2. Create implementation in `src/`
3. Add CMake option and conditional compilation
4. Update main.cpp to include new backend

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

[Add your license here]

## ğŸ™ Acknowledgments

- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) for STT
- [llama.cpp](https://github.com/ggerganov/llama.cpp) for LLM
- [Piper](https://github.com/rhasspy/piper) for TTS

